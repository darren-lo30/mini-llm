model_config: 
  vocab_size: 50304 
  embed_size: 256
  block_size: 256
  num_layers: 6
  num_attn_heads: 4
  p_dropout: 0.2
  ffn_hidden_dim_factor: 4
  bias: true
  attention_impl: 'normal'
checkpoint_file: null
batch_size: 64
num_grad_acc_steps: 1
device: 'mps'
data_path: './data'
learning_rate: 6.0e-4
num_steps: 1000
eval_freq: 100
log_freq: 100
save_freq: 500
save_dir: './out/shakespeare'
